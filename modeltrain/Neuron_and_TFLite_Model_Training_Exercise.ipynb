{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tKfHLCoEWhs"
      },
      "source": [
        "### Setup Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WeTTuPEjwGcd"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "print(\"Version: \", tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imNi21BFykq9"
      },
      "source": [
        "### Basic Neuron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uiPURnD1ykq9"
      },
      "outputs": [],
      "source": [
        "# To simulate XOR Neuron with input [[0.0,0.0], [0.0,1.0], [1.0,0.0], [1.0,1.0]] and output [[0],[1],[1],[0]]\n",
        "X = [tf.constant([[0.0,0.0]]),\n",
        "     tf.constant([[0.0,1.0]]),\n",
        "     tf.constant([[1.0,0.0]]),\n",
        "     tf.constant([[1.0,1.0]])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0FmE0BGykq9"
      },
      "outputs": [],
      "source": [
        "# Layer 1: Create 2 X 3 Weight (W1) and 1 X 3 bias (b1)\n",
        "W1 = tf.constant([[-1.1, 3.3, 2.8],\n",
        "                 [-1.0, 3.3, 2.8]])\n",
        "b1 = tf.constant([[ 0.0, 0.0, -2.8]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-wWf3g7ykq9"
      },
      "outputs": [],
      "source": [
        "# Layer 2: Create 3 X 1 Weight (W2) and 1 X 1 bias (b2)\n",
        "W2 = tf.constant([[ 0.5],\n",
        "                  [ 2.9 ],\n",
        "                  [-6.8]])\n",
        "b2 = tf.constant([[-4.6]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QVHfPE5Vykq9"
      },
      "outputs": [],
      "source": [
        "for i in range(4):\n",
        "    a1 = tf.matmul(X[i],W1) + b1\n",
        "    z1 = keras.activations.relu(a1)\n",
        "    a2 = tf.matmul(z1,W2) + b2\n",
        "    Y = keras.activations.sigmoid(a2)\n",
        "    print(X[i].numpy(),Y.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iU2HymXQykq9"
      },
      "source": [
        "### How to train XOR using NN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2KIJRxmcykq-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Define the XOR input and output data\n",
        "X = np.array([[0.0, 0.0], [0.0, 1.0], [1.0, 0.0], [1.0, 1.0]])\n",
        "y = np.array([[0.0], [1.0], [1.0], [0.0]])\n",
        "\n",
        "# Build the neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(3,input_dim=2,activation='relu'))  # Hidden layer with 3 neuron, input_dim=2, activation='relu'\n",
        "model.add(Dense(1,activation='sigmoid'))            # Output layer with 1 neuron, activation='sigmoid'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NygCt9Cuykq-"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6xgJUkRykq-"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "ADAM = tf.keras.optimizers.Adam(learning_rate=0.02) # learning_rate=0.02\n",
        "model.compile(optimizer=ADAM, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "EPOCHS = 200 # EPOCHS = 200\n",
        "model.fit(X, y, epochs=EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cTy-AgBeykq-"
      },
      "outputs": [],
      "source": [
        "model.predict(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgViJ2IO1ndb"
      },
      "source": [
        "## Cats and Dogs Small dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sB4hyvH_3Gz"
      },
      "source": [
        "#### Step 1: Import the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eyiql9-o_2ZX"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "\n",
        "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
        "\n",
        "# For PC\n",
        "# PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
        "\n",
        "# For Google Colab\n",
        "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_extracted','cats_and_dogs_filtered')\n",
        "\n",
        "PATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SaYHRDye_8v0"
      },
      "outputs": [],
      "source": [
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "meiYdejjAADV"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OkyUlE-g4KN6"
      },
      "outputs": [],
      "source": [
        "# Data Augmentation\n",
        "image_gen_train = ImageDataGenerator(\n",
        "                    rescale=1./255,\n",
        "                    rotation_range=45,\n",
        "                    width_shift_range=.15,\n",
        "                    height_shift_range=.15,\n",
        "                    horizontal_flip=True,\n",
        "                    zoom_range=0.5\n",
        "                    )\n",
        "image_gen_val = ImageDataGenerator(rescale=1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TBNK6kzB4Nrw"
      },
      "outputs": [],
      "source": [
        "# Batch Process\n",
        "train_data_gen = image_gen_train.flow_from_directory(batch_size=batch_size,\n",
        "                                                     directory=train_dir,\n",
        "                                                     shuffle=True,\n",
        "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                     class_mode='categorical')\n",
        "\n",
        "val_data_gen = image_gen_val.flow_from_directory(batch_size=batch_size,\n",
        "                                                 directory=validation_dir,\n",
        "                                                 target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                 class_mode='categorical')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMhbCYEJADYP"
      },
      "source": [
        "##### Visualize the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJkOuiCbf3Iq"
      },
      "outputs": [],
      "source": [
        "# This function will plot images in the form of a grid with 1 row and 5 columns where images are placed in each column.\n",
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip( images_arr, axes):\n",
        "        ax.imshow(img)\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "augmented_images = [train_data_gen[0][0][0] for i in range(5)]\n",
        "plotImages(augmented_images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRck3uIwyeLo"
      },
      "source": [
        "#### Step 2: Define  the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1QU9CT1u4WYH"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "model_batch_dropout_aug = Sequential([\n",
        "    Conv2D(32, 3, padding='same', activation='relu', input_shape = (IMG_HEIGHT, IMG_WIDTH,3)),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(128, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(128, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Flatten(),\n",
        "    # Drop Out layer\n",
        "    Dropout(0.3),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(2, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6naCWJHxygNk"
      },
      "source": [
        "#### Step 3: Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zWN9-NfR4Z5y"
      },
      "outputs": [],
      "source": [
        "ADAM = tf.keras.optimizers.Adam(learning_rate=0.0005)\n",
        "model_batch_dropout_aug.compile(optimizer=ADAM,loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "EPOCHS = 55\n",
        "history = model_batch_dropout_aug.fit(train_data_gen,epochs=EPOCHS,validation_data=val_data_gen)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4eKE0nEyxfk"
      },
      "source": [
        "#### Step 4: Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTVpfC2X4erj"
      },
      "outputs": [],
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhJI4mzTykrG"
      },
      "source": [
        "#### Step 5: Test the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fybRnmFCykrG"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "img_path=['cat.jpg','dog.jpg','test_cat.jpg','test_dog.jpg']\n",
        "\n",
        "for i in range(4):\n",
        "    img = image.load_img(img_path[i], target_size=(150, 150))\n",
        "    img_tensor = image.img_to_array(img)\n",
        "    img_tensor = np.expand_dims(img_tensor, axis=0)\n",
        "    img_tensor /= 255.\n",
        "\n",
        "    preds = model_batch_dropout_aug.predict(img_tensor)\n",
        "    output = np.argmax(preds)\n",
        "    label = 'cat' if output == 0 else 'dog'\n",
        "\n",
        "    plt.imshow(img_tensor[0])\n",
        "    plt.show()\n",
        "    print(preds)\n",
        "    print('The model prediction is ',label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QD9IE2dZvmx"
      },
      "source": [
        "#### Step 6: Save and Convert to tflite Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0PUBnomZvmx"
      },
      "outputs": [],
      "source": [
        "# Convert the model.\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model_batch_dropout_aug)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model.\n",
        "with open('cat_dog_model.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "us7rW6TaZvmx"
      },
      "outputs": [],
      "source": [
        "!pip install tflite-support-nightly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMu1BjcjZvmx"
      },
      "outputs": [],
      "source": [
        "from tflite_support.metadata_writers import image_classifier\n",
        "from tflite_support.metadata_writers import writer_utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WVYDvoLTZvmx"
      },
      "outputs": [],
      "source": [
        "ImageClassifierWriter = image_classifier.MetadataWriter\n",
        "_MODEL_PATH = \"cat_dog_model.tflite\"\n",
        "# Task Library expects label files that are in the same format as the one below.\n",
        "_LABEL_FILE = \"cat_dog_labels.txt\"\n",
        "_SAVE_TO_PATH = \"cat_dog_metadata.tflite\"\n",
        "_INPUT_NORM_MEAN = 127.5\n",
        "_INPUT_NORM_STD = 127.5\n",
        "\n",
        "# Create the metadata writer.\n",
        "writer = ImageClassifierWriter.create_for_inference(\n",
        "    writer_utils.load_file(_MODEL_PATH), [_INPUT_NORM_MEAN], [_INPUT_NORM_STD],\n",
        "    [_LABEL_FILE])\n",
        "\n",
        "# Verify the metadata generated by metadata writer.\n",
        "print(writer.get_metadata_json())\n",
        "\n",
        "# Populate the metadata into the model.\n",
        "writer_utils.save_file(writer.populate(), _SAVE_TO_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhzyPwHaykrI"
      },
      "source": [
        "# End of Worksheet"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "9hi9pgiAb_Wc",
        "bj0_-g09jL-S",
        "mbl5w8vDjTwU",
        "gfhIrE2fDRDv",
        "9wEuxiX_j56O",
        "cN_Ku2X91WlQ",
        "jPXFAwUl1b5V",
        "WgQGI9_41fSJ",
        "uY6tbfDe1j3k",
        "BgViJ2IO1ndb",
        "oD3qK9B4liVT",
        "TO3WCmo2nB-Q",
        "mQjlvPJKbuz1",
        "TsnfnOpnb5WG",
        "82INGsfHb_40",
        "KvXRTJg9cGVC",
        "xdCaSULmc786",
        "4Ta9YWWZdbiF",
        "D6mpaNGixeDu",
        "YRck3uIwyeLo",
        "6naCWJHxygNk",
        "u4eKE0nEyxfk",
        "kMaVg1zTKCIG",
        "1HeWq_7zY6oh",
        "G_aEYm4PVptX",
        "p_rU994OlLbm",
        "4VI_2v-MlQT5",
        "AliO7-3ZVY0R",
        "WExIKZPn3qX-",
        "Ij_t2sHPkNoF",
        "USwnLWZgajKz",
        "D4jRBKpSB-Ss",
        "loQBoU1AFk66"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}