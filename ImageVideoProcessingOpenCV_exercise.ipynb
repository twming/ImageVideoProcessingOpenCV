{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "21c83d29-9d55-4712-8eb0-d613cda5a3d4",
   "metadata": {},
   "source": [
    "# Topic 2 Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bf48a5-c4c4-484d-8b61-dd8a3e2cd4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check OpenCV Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844c2c9a-26d8-4f3e-bc2c-4a30144dc57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "cv.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d313760-e5c9-46ed-a983-5687f26760c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dc7e39-61d1-4f80-b693-2aa25ecad018",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "img = cv.imread(\"./images/butterfly.jpg\")\n",
    "cv.imshow(\"Display window\", img)\n",
    "\n",
    "k=cv.waitKey(0)\n",
    "if k == ord(\"q\"):\n",
    "    cv.imwrite(\"starry_night.png\", img)\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cb12b5-e52d-453e-aeee-38bcf40aaecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set permission to access USB Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12095f4e-828a-4758-b389-b56af9df3022",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo pi | sudo -S chmod 777 /dev/video0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9df9fb-797f-4322-95b9-9b2dba1a2953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Video - Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893d4a26-091f-42f2-9be9-fbfb7e7243ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv.VideoCapture(0)\n",
    "fourcc = cv.VideoWriter_fourcc(*'XVID')\n",
    "out = cv.VideoWriter('output.avi', fourcc, 20.0, (640,  480))\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv.flip(frame, 0)\n",
    "\n",
    "    out.write(frame)\n",
    "    cv.imshow('frame', frame)\n",
    "    if cv.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f1f24c-2a1c-4675-a2ac-76ec17eec49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Playing Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f19905-fa43-41dd-b41f-68c52b51ced7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "cap = cv.VideoCapture('output.avi')\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    cv.imshow('frame', gray)\n",
    "    if cv.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0bab5e-6fe9-4a1b-b90f-c98ef723f8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a black image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09896dc-c474-48d1-ab88-44fc40db7399",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "img = np.zeros((512,512,3), np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872cfa7a-ddfd-4030-8f0f-01e31ecd8fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a diagonal blue line with thickness of 5 px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3364651-89f0-4b42-a631-e31fbb4b2697",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.line(img,(0,0),(511,511),(255,0,0),5)\n",
    "cv.imshow(\"Display window\", img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b22639-1874-4322-bf37-556375f33c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a rectangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a316ca-b048-4e57-8cb1-e8651dd637e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.rectangle(img,(384,0),(510,128),(0,255,0),3)\n",
    "cv.imshow(\"Display window\", img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2925a4-8cac-4df4-8fa8-6382367ad53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d0ef89-87aa-4e93-be33-c957131c9a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.circle(img,(447,63), 63, (0,0,255), -1)\n",
    "cv.imshow(\"Display window\", img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6869bc59-e9ae-4de2-9a45-f16013b26577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a112c6-8282-47c6-a520-858c9ff66722",
   "metadata": {},
   "outputs": [],
   "source": [
    "pts = np.array([[10,5],[20,30],[70,20],[50,10]], np.int32)\n",
    "pts = pts.reshape((-1,1,2))\n",
    "cv.polylines(img,[pts],True,(0,255,255))\n",
    "cv.imshow(\"Display window\", img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8379e92-b0a1-42a0-a8b0-b5f6d4b0b87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f5f46f-e02c-404a-af7c-209d191ffd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "font = cv.FONT_HERSHEY_SIMPLEX\n",
    "cv.putText(img,'OpenCV',(10,500), font, 4,(255,255,255),2,cv.LINE_AA)\n",
    "cv.imshow(\"Display window\", img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b69a531-70eb-4f4e-bb98-7d041b1ec819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activity: Drawing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f4e60e-46cd-468b-bc84-93c1eb1abb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"./images/starry_night.jpg\")\n",
    "img = cv.resize(img, (640, 640))\n",
    "cv.rectangle(img,(120,150),(160,180),(0,255,0),3)\n",
    "cv.imshow(\"Display window\", img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d060f09-a2d4-46f8-8626-4c8f09d3d393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activity: Mouse Control (ESC to quit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a016845-b673-411d-96c5-4e6578ba1c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "drawing = False # true if mouse is pressed\n",
    "mode = False # if True, draw rectangle. Press 'm' to toggle to curve\n",
    "ix,iy = -1,-1\n",
    "## mouse callback function\n",
    "def draw_circle(event,x,y,flags,param):\n",
    "    global ix,iy,drawing,mode\n",
    "    if event == cv.EVENT_LBUTTONDOWN:\n",
    "        drawing = True\n",
    "        ix,iy = x,y\n",
    "    elif event == cv.EVENT_MOUSEMOVE:\n",
    "        if drawing == True:\n",
    "            if mode == True:\n",
    "                cv.rectangle(img,(ix,iy),(x,y),(0,255,0),-1)\n",
    "            else:\n",
    "                cv.circle(img,(x,y),5,(0,0,255),-1)\n",
    "    elif event == cv.EVENT_LBUTTONUP:\n",
    "        drawing = False\n",
    "        if mode == True:\n",
    "            cv.rectangle(img,(ix,iy),(x,y),(0,255,0),-1)\n",
    "        else:\n",
    "            cv.circle(img,(x,y),5,(0,0,255),-1)\n",
    "\n",
    " ## Create a black image, a window and bind the function to window\n",
    "img = np.zeros((512,512,3), np.uint8)\n",
    "cv.namedWindow('image')\n",
    "cv.setMouseCallback('image',draw_circle)\n",
    "while(1):\n",
    "    cv.imshow('image',img)\n",
    "    if cv.waitKey(20) & 0xFF == 27:\n",
    "        break\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9521127a-6b0b-4e05-a839-ea77e2e33cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing and Modifying Pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981e196a-1a2f-494d-b7a4-c30f1da8ec83",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"./images/butterfly.jpg\")\n",
    "k = cv.waitKey(0)\n",
    "px = img[100,100]\n",
    "print( px )\n",
    "img[100,100] = [255,255,255]\n",
    "px = img[100,100]\n",
    "print( px )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329d430c-e966-465b-91d5-50ea4ddc96eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert BRG to Gray Scale image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d032141-0acd-489c-8cb2-68e6581b0028",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"./images/butterfly.jpg\")\n",
    "gray = cv.cvtColor(img, cv.COLOR_RGB2GRAY)\n",
    "cv.imshow(\"Gray Scale\",gray)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ebca56-39b7-4c8a-90bd-3db13e4bd180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert BRG to HSV image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be4125a-969f-4111-9af6-8da9e26f2c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"./images/butterfly.jpg\")\n",
    "hsv = cv.cvtColor(img, cv.COLOR_BGR2HSV)\n",
    "cv.imshow(\"HSV\",hsv)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2392ff48-574d-433c-a890-87b67f98ef14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting BGR Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270d10b6-7f4d-4fcb-a1fa-e7d1ca0ef632",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"./images/starry_night.jpg\")\n",
    "img = cv.resize(img, (640, 640))\n",
    "cv.imshow(\"Original\", img)\n",
    "\n",
    "b,g,r = cv.split(img)\n",
    "cv.imshow(\"Blue\", b)\n",
    "cv.imshow(\"Green \", g)\n",
    "cv.imshow(\"Red\", r)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe85775-be87-409d-ae6b-db139a1f6bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting HSV Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0326fac1-dce6-44a2-91f5-628f59cdd02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"./images/starry_night.jpg\")\n",
    "img = cv.resize(img, (640, 640))\n",
    "cv.imshow(\"Original\", img)\n",
    "\n",
    "hsv = cv.cvtColor(img, cv.COLOR_BGR2HSV)\n",
    "cv.imshow(\"HSV\",hsv)\n",
    "\n",
    "h,s,v = cv.split(hsv)\n",
    "cv.imshow(\"Hue\", h)\n",
    "cv.imshow(\"Saturation \", s)\n",
    "cv.imshow(\"Value\", v)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee01b360-5a39-4c3c-9641-c4436314fd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd2323a-ec88-4eb0-a1c9-1d07e84536e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"./images/butterfly.jpg\")\n",
    "cv.imshow(\"Original\", img)\n",
    "\n",
    "b,g,r = cv.split(img)\n",
    "\n",
    "img2 = cv.add(b,g,r)\n",
    "cv.imshow(\"Merge\", img2)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ca978c-3810-4a4c-b3f1-dbf0af39ef0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activity: Splitting and Merging Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ce2492-2fb8-4c68-b58b-fe2f879a7691",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"./images/starry_night.jpg\")\n",
    "img = cv.resize(img, (640, 640))\n",
    "cv.imshow(\"Original\", img)\n",
    "\n",
    "b,g,r = cv.split(img)\n",
    "cv.imshow(\"Blue\", b)\n",
    "cv.imshow(\"Green \", g)\n",
    "cv.imshow(\"Red\", r)\n",
    "\n",
    "img2 = cv.merge((b,g,r))\n",
    "cv.imshow(\"Merged\", img2)\n",
    "\n",
    "img[:,:,2]=0\n",
    "cv.imshow(\"Modified\", img)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7433cdf-e183-4d6c-b0fc-6d56db6b1585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a0e821-9f53-4f7e-b093-e9873d0036c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"./images/butterfly.jpg\")\n",
    "\n",
    "cv.imshow(\"Original\", img)\n",
    "\n",
    "b,g,r = cv.split(img)\n",
    "\n",
    "img2 = cv.add(b,g,r)\n",
    "cv.imshow(\"Add\", img2)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4f93f2-ef1d-4ce5-99ed-0f9f534a4a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d6755e-6556-410b-8fe8-28ba957984fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv.imread(\"./images/butterfly.jpg\")\n",
    "img2 = cv.imread('./images/opencv-logo.png')\n",
    "\n",
    "height, width, _ = img1.shape\n",
    "\n",
    "# Resize img2 to match the size of img1\n",
    "img2_resized = cv.resize(img2, (width, height))\n",
    "\n",
    "dst=cv.addWeighted(img1,0.7,img2_resized,0.3,0.0)\n",
    "cv.imshow('dst',dst)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54b8db5-e9fc-4751-b86c-d2f5a14c88ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c51faa-77b5-45c9-9841-e9bb43f7953a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "img = cv.imread('./images/butterfly.jpg')\n",
    "cv.imshow(\"Original\", img)\n",
    "res = cv.resize(img,None,fx=2, fy=2, interpolation = cv.INTER_CUBIC)\n",
    "cv.imshow(\"Scaled\", res)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5278b6-4519-432f-813d-339c3912311a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944aad96-bcb5-4518-b286-9f6399f5de6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "img = cv.imread('./images/butterfly.jpg')\n",
    "rows,cols,_= img.shape\n",
    "\n",
    "M = np.float32([[1,0,100],[0,1,50]])\n",
    "dst = cv.warpAffine(img,M,(cols,rows))\n",
    "cv.imshow('img',dst)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bb7440-095f-404e-b3a7-758448d8b82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb6810f-41f7-40dc-bd0a-d9be699c9126",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('./images/butterfly.jpg',0)\n",
    "rows,cols = img.shape\n",
    "\n",
    "# cols-1 and rows-1 are the coordinate limits.\n",
    "M = cv.getRotationMatrix2D(((cols-1)/2.0,(rows-1)/2.0),90,1)\n",
    "dst = cv.warpAffine(img,M,(cols,rows))\n",
    "\n",
    "cv.imshow('img',dst)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60728246-fd19-44a3-80cd-07c517568f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affline Transformation\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv.imread('./images/butterfly.jpg')\n",
    "rows,cols,ch = img.shape\n",
    "\n",
    "pts1 = np.float32([[50,50],[200,50],[50,200]])\n",
    "pts2 = np.float32([[10,100],[200,50],[100,250]])\n",
    "M = cv.getAffineTransform(pts1,pts2)\n",
    "dst = cv.warpAffine(img,M,(cols,rows))\n",
    "\n",
    "plt.subplot(121),plt.imshow(img),plt.title('Input')\n",
    "plt.subplot(122),plt.imshow(dst),plt.title('Output')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42d1d56-5671-435f-8802-a6f09a9b7e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perspective Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f589d92d-52b0-481c-b811-0917febf3b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv.imread('./images/sudoku.png')\n",
    "rows,cols,_ = img.shape\n",
    "\n",
    "pts1 = np.float32([[56,65],[368,52],[28,387],[389,390]])\n",
    "pts2 = np.float32([[0,0],[300,0],[0,300],[300,300]])\n",
    "M = cv.getPerspectiveTransform(pts1,pts2)\n",
    "dst = cv.warpPerspective(img,M,(300,300))\n",
    "\n",
    "plt.subplot(121),plt.imshow(img),plt.title('Input')\n",
    "plt.subplot(122),plt.imshow(dst),plt.title('Output')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae20d85-cd98-41a2-9528-c1d113ea3278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D Convolution ( Image Filtering )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88296011-fdc5-4efd-b937-87ccd16dccd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv.imread('./images/butterfly.jpg')\n",
    "kernel = np.ones((5,5),np.float32)/25\n",
    "dst = cv.filter2D(img,-1,kernel)\n",
    "\n",
    "plt.subplot(121),plt.imshow(img),plt.title('Original')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122),plt.imshow(dst),plt.title('Averaging')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6332755-35f7-448e-be09-bbe3535c56a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Averaging Blurring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ddac14-945c-4eb2-ac1c-36bd0bcf83fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "img = cv.imread('./images/opencv-logo.png')\n",
    "blur = cv.blur(img,(5,5))\n",
    "plt.subplot(121),plt.imshow(img),plt.title('Original')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122),plt.imshow(blur),plt.title('Blurred')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99db94cf-eded-4f71-90bc-da23a87bda7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guassian Blurring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696bb8da-4481-4983-82c7-dd0ca7d8ee0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "img = cv.imread('./images/opencv-logo.png')\n",
    "blur = cv.GaussianBlur(img,(5,5),0)\n",
    "plt.subplot(121),plt.imshow(img),plt.title('Original')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122),plt.imshow(blur),plt.title('Blurred')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4407c43d-ae86-4735-8d01-0093ff012a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erosion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3146e06-3034-48e7-8ef6-9d2a804a7d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv.imread(\"./images/starry_night.jpg\")\n",
    "#img = cv.imread(\"./images/wafermap.png\")\n",
    "\n",
    "kernel = np.ones((5,5),np.uint8)\n",
    "erosion = cv.erode(img,kernel,iterations = 1)\n",
    "dilatation = cv.dilate(erosion, kernel)\n",
    "\n",
    "plt.subplot(131),plt.imshow(img),plt.title('Original')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(132),plt.imshow(erosion),plt.title('Erosion')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(133),plt.imshow(dilatation),plt.title('Dilatation')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1fb3072e-1ad7-4168-a52d-35c977910bd1",
   "metadata": {},
   "source": [
    "# Topic 3 Feature Extraction and Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9e313d-9e7e-4ec3-ab6f-07be7434c384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Harris Corner Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468d31da-a41a-4b80-a7f3-b72fe0a585e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "filename = './images/chess.jpg'\n",
    "img = cv.imread(filename)\n",
    "gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "\n",
    "gray = np.float32(gray)\n",
    "dst = cv.cornerHarris(gray,2,3,0.04)\n",
    "\n",
    "## result is dilated for marking the corners, not important\n",
    "dst = cv.dilate(dst,None)\n",
    "\n",
    "## Threshold for an optimal value, it may vary depending on the image.\n",
    "img[dst>0.01*dst.max()]=[0,0,255]\n",
    "cv.imshow('dst',img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7408544-e5fa-4faa-930c-c5d3a4870f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIFT (Scale-Invariant Feature Transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6520ea1e-bf03-4d39-b021-8ab02950fae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "#img = cv.imread('./images/building.jpg')\n",
    "img = cv.imread('./images/chess.jpg')\n",
    "\n",
    "gray= cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "sift = cv.SIFT_create()\n",
    "\n",
    "kp = sift.detect(gray,None)\n",
    "img=cv.drawKeypoints(gray,kp,img)\n",
    "cv.imwrite('sift_keypoints.jpg',img)\n",
    "\n",
    "cv.imshow('sift_keypoints',img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98a72a3-ed21-4c83-a339-f8420cd641ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "## FAST Algorithm for Corner Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c74277-b01c-49e4-a541-d06761b8c823",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#img = cv.imread('./images/building.jpg',0)\n",
    "img = cv.imread('./images/chess.jpg',0)\n",
    "\n",
    "## Initiate FAST object with default values\n",
    "fast = cv.FastFeatureDetector_create()\n",
    "\n",
    "## find and draw the keypoints\n",
    "kp = fast.detect(img,None)\n",
    "img2 = cv.drawKeypoints(img, kp, None, color=(255,0,0))\n",
    "\n",
    "## Print all default params\n",
    "print( \"Threshold: {}\".format(fast.getThreshold()) )\n",
    "print( \"nonmaxSuppression:{}\".format(fast.getNonmaxSuppression()) )\n",
    "print( \"neighborhood: {}\".format(fast.getType()) )\n",
    "print( \"Total Keypoints with nonmaxSuppression: {}\".format(len(kp)) )\n",
    "cv.imwrite('fast_true.png',img2)\n",
    "\n",
    "## Disable nonmaxSuppression\n",
    "fast.setNonmaxSuppression(0)\n",
    "kp = fast.detect(img,None)\n",
    "print( \"Total Keypoints without nonmaxSuppression: {}\".format(len(kp)) )\n",
    "img3 = cv.drawKeypoints(img, kp, None, color=(255,0,0))\n",
    "cv.imwrite('fast_false.png',img3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff71841-1951-415d-94bb-e1d8b97cc424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threhsolding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7857b45-95eb-4ef3-a027-47b15c7a784c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv.imread('./images/detect_blob.png', 0)\n",
    "threshold = 150\n",
    "\n",
    "height, width = img.shape[0:2]\n",
    "cv.imshow(\"Original BW\",img)\n",
    "\n",
    "# CV2 Thresholding\n",
    "ret,thresh = cv.threshold(img,threshold,255,cv.THRESH_BINARY)\n",
    "ret,thresh2 = cv.threshold(img,threshold,255,cv.THRESH_BINARY_INV)\n",
    "ret,thresh3 = cv.threshold(img,threshold,255,cv.THRESH_TRUNC)\n",
    "ret,thresh4 = cv.threshold(img,threshold,255,cv.THRESH_TOZERO)\n",
    "ret,thresh5 = cv.threshold(img,threshold,255,cv.THRESH_TOZERO_INV)\n",
    "\n",
    "cv.imshow(\"THRESH_BINARY\",thresh)\n",
    "cv.imshow(\"THRESH_BINARY_INV\",thresh2)\n",
    "cv.imshow(\"THRESH_TRUNC\",thresh3)\n",
    "cv.imshow(\"THRESH_TOZERO\",thresh4)\n",
    "cv.imshow(\"THRESH_TOZERO_INV\",thresh5)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9595d2-62d9-4480-b8d1-143ad619ff6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activity: Thresholding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995a55a3-65dd-46e0-b884-19023c6c05bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv.imread('./images/opencv-logo.png', 0)\n",
    "threshold = 150\n",
    "ret,thresh = cv.threshold(img1,threshold,255,cv.THRESH_BINARY)\n",
    "ret,thresh2 = cv.threshold(img1,threshold,255,cv.THRESH_BINARY_INV)\n",
    "ret,thresh3 = cv.threshold(img1,threshold,255,cv.THRESH_TRUNC)\n",
    "ret,thresh4 = cv.threshold(img1,threshold,255,cv.THRESH_TOZERO)\n",
    "ret,thresh5 = cv.threshold(img1,threshold,255,cv.THRESH_TOZERO_INV)\n",
    "\n",
    "cv.imshow(\"THRESH_BINARY\",thresh)\n",
    "cv.imshow(\"THRESH_BINARY_INV\",thresh2)\n",
    "cv.imshow(\"THRESH_TRUNC\",thresh3)\n",
    "cv.imshow(\"THRESH_TOZERO\",thresh4)\n",
    "cv.imshow(\"THRESH_TOZERO_INV\",thresh5)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb1e91a-4e63-459b-993d-8f1e319acdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adaptive Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e67b57-42f2-4d56-9ce0-d72714ab88f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('./images/sudoku.png',0)\n",
    "cv.imshow(\"Original\",img)\n",
    "\n",
    "ret, thresh_basic = cv.threshold(img,70,255,cv.THRESH_BINARY)\n",
    "plt.imshow(thresh_basic,cmap='gray')\n",
    "plt.show()\n",
    "cv.imshow(\"Basic Binary\",thresh_basic)\n",
    "\n",
    "thres_adapt = cv.adaptiveThreshold(img, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, 115, 1)\n",
    "plt.imshow(thres_adapt ,cmap='gray')\n",
    "plt.show()\n",
    "cv.imshow(\"Adaptive Threshold\",thres_adapt)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b9e668-0bb6-4961-9291-a666a9205d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activity: Adaptive Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213e1740-f768-453e-87e9-4a42e8843133",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('./images/opencv-logo.png', 0)\n",
    "thres_adapt = cv.adaptiveThreshold(img, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, 115, 1)\n",
    "cv.imshow(\"Adaptive Threshold\",thres_adapt)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60d9a38-2d1b-4771-8a67-809ac62e54bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Canny Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d804fa-100e-4671-9b44-484e05e7e298",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"./images/tomatoes.jpg\",1)\n",
    "\n",
    "hsv = cv.cvtColor(img, cv.COLOR_BGR2HSV)\n",
    "res,thresh = cv.threshold(hsv[:,:,0], 25, 255, cv.THRESH_BINARY_INV)\n",
    "\n",
    "edges = cv.Canny(img, 100, 70)\n",
    "cv.imshow(\"Canny\",edges)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022cbe3e-323b-45fd-b396-eaab79e83a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808d2e80-8af4-4602-8de9-538aa82e050b",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = cv.imread('./images/template.jpg',0)\n",
    "frame = cv.imread(\"./images/players.jpg\",0)\n",
    "\n",
    "cv.imshow(\"Frame\",frame)\n",
    "cv.imshow(\"Template\",template)\n",
    "\n",
    "result = cv.matchTemplate(frame, template, cv.TM_CCOEFF_NORMED)\n",
    "\n",
    "min_val, max_val, min_loc, max_loc = cv.minMaxLoc(result)\n",
    "print(max_val,max_loc)\n",
    "cv.circle(result,max_loc, 15,255,2)\n",
    "\n",
    "cv.imwrite(\"./images/screenshot.jpg\",result)\n",
    "img = Image.open('./images/screenshot.jpg')\n",
    "img.show()\n",
    "\n",
    "cv.imshow(\"Matching\",result)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "da7ab78b-64d5-4851-8fcd-71cd44846556",
   "metadata": {},
   "source": [
    "# Topic 4 Machine Learning Based Computer Vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34952931-9271-448e-92c1-770f629b8a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Haar Cascade Face Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f65635a-4a4c-4b76-9df6-565de53d07ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"./images/faces.jpeg\",1)\n",
    "gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "path = \"./HaarCascade/haarcascade_frontalface_default.xml\"\n",
    "\n",
    "face_cascade = cv.CascadeClassifier(path)\n",
    "\n",
    "faces = face_cascade.detectMultiScale(gray, scaleFactor=1.10, minNeighbors=5, minSize=(40,40))\n",
    "print(len(faces))\n",
    "\n",
    "for (x, y, w, h) in faces:\n",
    "\tcv.rectangle(img, (x,y), (x+w,y+h), (0,255,0), 2)\n",
    "\n",
    "cv.imwrite(\"./images/screenshot.jpg\",img)\n",
    "img = Image.open('./images/screenshot.jpg')\n",
    "img.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a67a47e-b3f3-41b5-ac7e-01a95fa066b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activity: Haar Cascade Face Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6014182-1fb3-41ce-8cf7-00bf1cd44e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv.CascadeClassifier('./HaarCascade/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv.CascadeClassifier('./HaarCascade/haarcascade_eye.xml')\n",
    "img = cv.imread('./images/children.jpg',1)\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "for (x,y,w,h) in faces:\n",
    "    cv.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = img[y:y+h, x:x+w]\n",
    "    eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "    for (ex,ey,ew,eh) in eyes:\n",
    "        cv.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "\n",
    "cv.imshow('img',img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db7cc9b-dea5-41c3-91b2-9c2ba2581b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activity: Haar Cascade Eye Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fa7130-eb09-406b-8ccb-2f8c769e7d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"./images/faces.jpeg\",1)\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "path = \"./HaarCascade/haarcascade_eye.xml\"\n",
    "\n",
    "eye_cascade = cv.CascadeClassifier(path)\n",
    "\n",
    "eyes = eye_cascade.detectMultiScale(gray, scaleFactor=1.02,minNeighbors=20,minSize=(10,10))\n",
    "print(len(eyes))\n",
    "\n",
    "for (x, y, w, h) in eyes:\n",
    "\txc = (x + x+w)/2\n",
    "\tyc = (y + y+h)/2\n",
    "\tradius = w/2\n",
    "\tcv.circle(img, (int(xc),int(yc)), int(radius), (255,0,0), 2)\n",
    "\n",
    "cv.imshow(\"Eyes\",img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2068c817-9d21-4a25-aef0-7837bbde8766",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Activity: Haar-Cascade Face Detecton with Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317bd184-a719-4bb9-827f-09a928b14640",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install easydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0db125-7f4d-4773-8239-8479cd8e3eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import cv2 as cv\n",
    "#import argparse\n",
    "import easydict\n",
    "def detectAndDisplay(frame):\n",
    "    frame_gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    frame_gray = cv.equalizeHist(frame_gray)\n",
    "    #-- Detect faces\n",
    "    faces = face_cascade.detectMultiScale(frame_gray)\n",
    "    for (x,y,w,h) in faces:\n",
    "        center = (x + w//2, y + h//2)\n",
    "        frame = cv.ellipse(frame, center, (w//2, h//2), 0, 0, 360, (255, 0, 255), 4)\n",
    "        faceROI = frame_gray[y:y+h,x:x+w]\n",
    "        #-- In each face, detect eyes\n",
    "        eyes = eyes_cascade.detectMultiScale(faceROI)\n",
    "        for (x2,y2,w2,h2) in eyes:\n",
    "            eye_center = (x + x2 + w2//2, y + y2 + h2//2)\n",
    "            radius = int(round((w2 + h2)*0.25))\n",
    "            frame = cv.circle(frame, eye_center, radius, (255, 0, 0 ), 4)\n",
    "    cv.imshow('Capture - Face detection', frame)\n",
    "\n",
    "args = easydict.EasyDict({\n",
    "    \"face_cascade\": './HaarCascade/haarcascade_frontalface_alt.xml',\n",
    "    \"eyes_cascade\": './HaarCascade/haarcascade_eye_tree_eyeglasses.xml',\n",
    "    \"camera\": 0\n",
    "})\n",
    "#parser = argparse.ArgumentParser(description='Code for Cascade Classifier tutorial.')\n",
    "#parser.add_argument('--face_cascade', help='Path to face cascade.', default='./HaarCascade/haarcascade_frontalface_alt.xml')\n",
    "#parser.add_argument('--eyes_cascade', help='Path to eyes cascade.', default='./HaarCascade/haarcascade_eye_tree_eyeglasses.xml')\n",
    "#parser.add_argument('--camera', help='Camera divide number.', type=int, default=0)\n",
    "#args = parser.parse_args()\n",
    "face_cascade_name = args.face_cascade\n",
    "eyes_cascade_name = args.eyes_cascade\n",
    "face_cascade = cv.CascadeClassifier()\n",
    "eyes_cascade = cv.CascadeClassifier()\n",
    "#-- 1. Load the cascades\n",
    "if not face_cascade.load(cv.samples.findFile(face_cascade_name)):\n",
    "    print('--(!)Error loading face cascade')\n",
    "    exit(0)\n",
    "if not eyes_cascade.load(cv.samples.findFile(eyes_cascade_name)):\n",
    "    print('--(!)Error loading eyes cascade')\n",
    "    exit(0)\n",
    "camera_device = args.camera\n",
    "#-- 2. Read the video stream\n",
    "cap = cv.VideoCapture(camera_device)\n",
    "if not cap.isOpened:\n",
    "    print('--(!)Error opening video capture')\n",
    "    exit(0)\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if frame is None:\n",
    "        print('--(!) No captured frame -- Break!')\n",
    "        break\n",
    "    detectAndDisplay(frame)\n",
    "    if cv.waitKey(10) == 27:\n",
    "        cap.release()\n",
    "        cv.destroyAllWindows()\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38d86c7-ec26-475d-94d8-acaac700cf86",
   "metadata": {},
   "source": [
    "# Topic 5 Video Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a3705a-ef2e-4031-b715-0c492e0f0d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Background Substraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed6b837-22c0-4194-8513-511e883df7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import cv2 as cv\n",
    "#import argparse\n",
    "import easydict\n",
    "\n",
    "args = easydict.EasyDict({\n",
    "    \"input\": './videos/vtest.mp4',\n",
    "    \"algo\": 'MOG2'\n",
    "})\n",
    "#parser = argparse.ArgumentParser(description='This program shows how to use background subtraction methods provided by \\\n",
    "#                                              OpenCV. You can process both videos and images.')\n",
    "#parser.add_argument('--input', type=str, help='Path to a video or a sequence of image.', default='vtest.avi')\n",
    "#parser.add_argument('--input', type=str, help='Background subtraction method (KNN, MOG2).', default='MOG2')\n",
    "#args = parser.parse_args()\n",
    "if args.algo == 'MOG2':\n",
    "    backSub = cv.createBackgroundSubtractorMOG2()\n",
    "else:\n",
    "    backSub = cv.createBackgroundSubtractorKNN()\n",
    "capture = cv.VideoCapture(cv.samples.findFileOrKeep(args.input))\n",
    "if not capture.isOpened:\n",
    "    print('Unable to open: ' + args.input)\n",
    "    exit(0)\n",
    "while True:\n",
    "    ret, frame = capture.read()\n",
    "    if frame is None:\n",
    "        break\n",
    "    \n",
    "    fgMask = backSub.apply(frame)\n",
    "        \n",
    "    cv.rectangle(frame, (10, 2), (100,20), (255,255,255), -1)\n",
    "    cv.putText(frame, str(capture.get(cv.CAP_PROP_POS_FRAMES)), (15, 15),\n",
    "               cv.FONT_HERSHEY_SIMPLEX, 0.5 , (0,0,0))\n",
    "\n",
    "    \n",
    "    cv.imshow('Frame', frame)\n",
    "    cv.imshow('FG Mask', fgMask)\n",
    "    \n",
    "    keyboard = cv.waitKey(30)\n",
    "    if keyboard == 'q' or keyboard == 27:\n",
    "        cap.release()\n",
    "        cv.destroyAllWindows()\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e9c316-9b7f-4875-9ee2-ce4fe4e57515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object Tracking with Meanshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea93b37-11a3-4c68-bce6-474a57cfe5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "#import argparse\n",
    "import easydict\n",
    "\n",
    "args = easydict.EasyDict({\n",
    "    \"image\": 'https://www.bogotobogo.com/python/OpenCV_Python/images/mean_shift_tracking/slow_traffic_small.mp4'\n",
    "})\n",
    "#parser = argparse.ArgumentParser(description='This sample demonstrates the meanshift algorithm. \\\n",
    "#                                              The example file can be downloaded from: \\\n",
    "#                                              https://www.bogotobogo.com/python/OpenCV_Python/images/mean_shift_tracking/slow_traffic_small.mp4')\n",
    "#parser.add_argument('image', type=str, help='path to image file')\n",
    "#args = parser.parse_args()\n",
    "\n",
    "cap = cv.VideoCapture(args.image)\n",
    "# take first frame of the video\n",
    "ret,frame = cap.read()\n",
    "# setup initial location of window\n",
    "x, y, w, h = 300, 200, 100, 50 # simply hardcoded the values\n",
    "track_window = (x, y, w, h)\n",
    "# set up the ROI for tracking\n",
    "roi = frame[y:y+h, x:x+w]\n",
    "hsv_roi =  cv.cvtColor(roi, cv.COLOR_BGR2HSV)\n",
    "mask = cv.inRange(hsv_roi, np.array((0., 60.,32.)), np.array((180.,255.,255.)))\n",
    "roi_hist = cv.calcHist([hsv_roi],[0],mask,[180],[0,180])\n",
    "cv.normalize(roi_hist,roi_hist,0,255,cv.NORM_MINMAX)\n",
    "# Setup the termination criteria, either 10 iteration or move by atleast 1 pt\n",
    "term_crit = ( cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 10, 1 )\n",
    "while(1):\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        hsv = cv.cvtColor(frame, cv.COLOR_BGR2HSV)\n",
    "        dst = cv.calcBackProject([hsv],[0],roi_hist,[0,180],1)\n",
    "        # apply meanshift to get the new location\n",
    "        ret, track_window = cv.meanShift(dst, track_window, term_crit)\n",
    "        # Draw it on image\n",
    "        x,y,w,h = track_window\n",
    "        img2 = cv.rectangle(frame, (x,y), (x+w,y+h), 255,2)\n",
    "        cv.imshow('img2',img2)\n",
    "        k = cv.waitKey(30) & 0xff\n",
    "        if k == 27:\n",
    "            cap.release()\n",
    "            cv.destroyAllWindows()\n",
    "            break\n",
    "    else:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09585653-99bd-44bf-a89e-6aa911756b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object Tracking with CAMshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f379240e-29b9-43d4-9159-7b3849787e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "#import argparse\n",
    "args = easydict.EasyDict({\n",
    "    \"image\": 'https://www.bogotobogo.com/python/OpenCV_Python/images/mean_shift_tracking/slow_traffic_small.mp4'\n",
    "})\n",
    "#parser = argparse.ArgumentParser(description='This sample demonstrates the camshift algorithm. \\\n",
    "#                                              The example file can be downloaded from: \\\n",
    "#                                              https://www.bogotobogo.com/python/OpenCV_Python/images/mean_shift_tracking/slow_traffic_small.mp4')\n",
    "#parser.add_argument('image', type=str, help='path to image file')\n",
    "#args = parser.parse_args()\n",
    "\n",
    "cap = cv.VideoCapture(args.image)\n",
    "# take first frame of the video\n",
    "ret,frame = cap.read()\n",
    "# setup initial location of window\n",
    "x, y, w, h = 300, 200, 100, 50 # simply hardcoded the values\n",
    "track_window = (x, y, w, h)\n",
    "# set up the ROI for tracking\n",
    "roi = frame[y:y+h, x:x+w]\n",
    "hsv_roi =  cv.cvtColor(roi, cv.COLOR_BGR2HSV)\n",
    "mask = cv.inRange(hsv_roi, np.array((0., 60.,32.)), np.array((180.,255.,255.)))\n",
    "roi_hist = cv.calcHist([hsv_roi],[0],mask,[180],[0,180])\n",
    "cv.normalize(roi_hist,roi_hist,0,255,cv.NORM_MINMAX)\n",
    "# Setup the termination criteria, either 10 iteration or move by atleast 1 pt\n",
    "term_crit = ( cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 10, 1 )\n",
    "while(1):\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        hsv = cv.cvtColor(frame, cv.COLOR_BGR2HSV)\n",
    "        dst = cv.calcBackProject([hsv],[0],roi_hist,[0,180],1)\n",
    "        # apply camshift to get the new location\n",
    "        ret, track_window = cv.CamShift(dst, track_window, term_crit)\n",
    "        # Draw it on image\n",
    "        pts = cv.boxPoints(ret)\n",
    "        pts = np.intp(pts)\n",
    "        img2 = cv.polylines(frame,[pts],True, 255,2)\n",
    "        cv.imshow('img2',img2)\n",
    "        k = cv.waitKey(30) & 0xff\n",
    "        if k == 27:\n",
    "            cap.release()\n",
    "            cv.destroyAllWindows()\n",
    "            break\n",
    "    else:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9894309-6b31-42fd-81d7-6673ef02e8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dense Optical Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a8f65d-9eb2-4707-9df5-d0541a2f96fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "cap = cv.VideoCapture(cv.samples.findFile(\"./videos/vtest.mp4\"))\n",
    "ret, frame1 = cap.read()\n",
    "prvs = cv.cvtColor(frame1,cv.COLOR_BGR2GRAY)\n",
    "hsv = np.zeros_like(frame1)\n",
    "hsv[...,1] = 255\n",
    "while(1):\n",
    "    ret, frame2 = cap.read()\n",
    "    next = cv.cvtColor(frame2,cv.COLOR_BGR2GRAY)\n",
    "    flow = cv.calcOpticalFlowFarneback(prvs,next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    mag, ang = cv.cartToPolar(flow[...,0], flow[...,1])\n",
    "    hsv[...,0] = ang*180/np.pi/2\n",
    "    hsv[...,2] = cv.normalize(mag,None,0,255,cv.NORM_MINMAX)\n",
    "    bgr = cv.cvtColor(hsv,cv.COLOR_HSV2BGR)\n",
    "    cv.imshow('frame2',bgr)\n",
    "    k = cv.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        cap.release()\n",
    "        cv.destroyAllWindows()\n",
    "        break\n",
    "    elif k == ord('s'):\n",
    "        cv.imwrite('opticalfb.png',frame2)\n",
    "        cv.imwrite('opticalhsv.png',bgr)\n",
    "    prvs = next\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42bc449-44eb-4599-95ee-156363d2899d",
   "metadata": {},
   "source": [
    "# --The End--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6787d463-feb1-41c0-9fcb-155745cf8841",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
